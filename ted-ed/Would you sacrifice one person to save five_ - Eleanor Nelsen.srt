1
00:00:06,859 --> 00:00:11,381
想象你眼前有一辆失控的电车，
飞速冲下轨道，

2
00:00:11,381 --> 00:00:15,821
轨道前方有5个工人，难逃此劫。

3
00:00:15,821 --> 00:00:18,049
而你正巧站在道岔旁边,

4
00:00:18,049 --> 00:00:21,480
可以将电车引向另一条轨道上。

5
00:00:21,480 --> 00:00:22,830
那么，问题来了,

6
00:00:22,830 --> 00:00:26,989
另一条轨道上面也有工人，
但是只有一个。

7
00:00:27,799 --> 00:00:29,170
这时候，你会怎么办？

8
00:00:29,170 --> 00:00:32,685
你会选择牺牲一个人来挽救五个人吗？

9
00:00:32,685 --> 00:00:35,334
这就是我们所说的电车难题，

10
00:00:35,334 --> 00:00:41,873
是由哲学家菲利帕福特
在1967年提出的道德困境问题。

11
00:00:41,873 --> 00:00:45,591
这个问题能引起大家的兴趣
是因为它促使我们思考

12
00:00:45,591 --> 00:00:47,890
如何在困境之中做出抉择。

13
00:00:47,890 --> 00:00:50,200
我们应该选择一个最好的结果，

14
00:00:50,200 --> 00:00:54,980
还是坚守不做出任何伤害
他人生命的行为道德准则？

15
00:00:54,980 --> 00:01:00,667
一项调查显示，
大约90%的参与者选择搬动道岔，

16
00:01:00,670 --> 00:01:04,090
牺牲一人来拯救五个人的生命，

17
00:01:04,090 --> 00:01:08,430
其他试验，包括一个虚拟现实模拟研究

18
00:01:08,430 --> 00:01:10,600
也得出了相似的结果。

19
00:01:10,830 --> 00:01:15,781
这与功利主义的观点相吻合，

20
00:01:15,781 --> 00:01:18,521
即认为道德上正确的决定是依据

21
00:01:18,521 --> 00:01:23,181
为最多的人提供最大的利益
这一原则做出的。

22
00:01:23,181 --> 00:01:25,481
五个人的生命总归大于一个人的生命，

23
00:01:25,481 --> 00:01:30,462
即便是以牺牲一个人的生命为代价。

24
00:01:30,462 --> 00:01:33,321
然而人们并不都遵循功利主义的思想，

25
00:01:33,321 --> 00:01:36,942
我们从电车难题的变式中就可以发现。

26
00:01:36,942 --> 00:01:40,183
这一次，你站在天桥上，

27
00:01:40,183 --> 00:01:42,992
一辆失控的电车正朝你驶来。

28
00:01:42,992 --> 00:01:44,703
此时并没有第二条轨道，

29
00:01:44,703 --> 00:01:48,604
但是你的旁边站着
一位体型庞大的男人。

30
00:01:48,604 --> 00:01:52,372
如果你把他推下天桥，
他的身体能够让电车停下来，

31
00:01:52,372 --> 00:01:53,993
拯救五个人的性命。

32
00:01:53,993 --> 00:01:55,893
但是，那个男人会牺牲。

33
00:01:55,893 --> 00:01:59,272
对于功利主义者而言，
这一次选择与上一次相同，

34
00:01:59,272 --> 00:02:01,792
牺牲一个人来拯救另五个人。

35
00:02:01,792 --> 00:02:04,652
但是在这次试验中，
只有大约10%的参与者

36
00:02:04,664 --> 00:02:08,312
认为可以把那个男人推落到轨道上。

37
00:02:08,312 --> 00:02:11,914
直觉告诉我们，
故意造成他人死亡的行为

38
00:02:11,914 --> 00:02:16,203
不同于间接伤害造成死亡。

39
00:02:16,203 --> 00:02:20,703
这属于人之常情，
其背后的原因很难解释清楚。

40
00:02:20,703 --> 00:02:23,473
正是道德伦理与心理学产生的交集

41
00:02:23,473 --> 00:02:26,454
让电车难题变得非常有意思。

42
00:02:26,454 --> 00:02:30,984
电车难题及其多种变式
揭示了我们在做出道德判断时

43
00:02:30,984 --> 00:02:36,195
依赖于多种因素，
而非仅仅通过合乎逻辑的利弊权衡。

44
00:02:36,195 --> 00:02:38,835
比如说，
男性比女性更有可能选择

45
00:02:38,835 --> 00:02:42,404
把那个男人推下天桥。

46
00:02:42,404 --> 00:02:46,834
参加试验之前看了喜剧片的人，
也更可能做出同样的选择。

47
00:02:46,834 --> 00:02:49,165
一项虚拟现实研究发现，

48
00:02:49,165 --> 00:02:52,944
相较女性，人们更愿意选择牺牲男性。

49
00:02:52,944 --> 00:02:55,214
研究人员在探究

50
00:02:55,214 --> 00:02:59,445
原始电车难题及其变式情形下
人们的脑部活动时发现，

51
00:02:59,445 --> 00:03:04,044
两种情景都激发了
脑部负责有意识决策和

52
00:03:04,044 --> 00:03:06,344
情绪反应的部位。

53
00:03:06,344 --> 00:03:10,975
但是在变式情况中， 
参与者的情绪反应更加激烈。

54
00:03:10,975 --> 00:03:13,234
脑部负责处理

55
00:03:13,234 --> 00:03:16,694
内部冲突的部位也更加活跃。

56
00:03:16,694 --> 00:03:17,966
为什么会产生这些变化？

57
00:03:17,966 --> 00:03:22,642
一种解释是，把人推下桥致死
对个人的冲击更大，

58
00:03:22,642 --> 00:03:26,735
激发了对于杀人行为的厌恶之情，

59
00:03:26,735 --> 00:03:31,424
但是我们又很矛盾，
因为我们知道这是符合逻辑的选择。

60
00:03:31,424 --> 00:03:36,405
一些哲学家和心理学家
对电车难题持批评态度。

61
00:03:36,405 --> 00:03:41,266
他们认为这并没有揭示任何东西，
因为问题发生的前提非常不现实，

62
00:03:41,266 --> 00:03:45,325
以致于试验参与者并不会认真对待。

63
00:03:45,325 --> 00:03:48,556
然而，新科技正让这种道德分析

64
00:03:48,556 --> 00:03:50,488
变得比以往更加重要。

65
00:03:50,488 --> 00:03:54,036
比如说，
无人驾驶的汽车可能会面临

66
00:03:54,036 --> 00:03:58,007
造成小事故来避免大事故的选择。

67
00:03:58,007 --> 00:04:01,626
同时，政府在研发军用无人机

68
00:04:01,626 --> 00:04:05,976
最终能够做出牺牲平民生命

69
00:04:05,976 --> 00:04:09,276
以攻击高价值目标的决定。

70
00:04:09,276 --> 00:04:11,197
如果我们希望这样的行为
变得合乎道德，

71
00:04:11,197 --> 00:04:15,397
那么我们必须首先决定
如何衡量人类生命的价值，

72
00:04:15,397 --> 00:04:17,577
并评判什么是符合多数人利益的。

73
00:04:17,577 --> 00:04:20,107
那么，独立系统的研究人员

74
00:04:20,107 --> 00:04:22,207
应该和哲学家一起处理

75
00:04:22,207 --> 00:04:27,628
机器编程过程中遇到的道德难题，

76
00:04:27,628 --> 00:04:30,957
而这正恰恰说明了假设中的困境，

77
00:04:30,957 --> 00:00:00,000
最终也会与现实世界发生碰撞。

